<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Cross-validation &#8211; Smart Digital Agriculture</title>
<meta name="description" content="">


<!-- Twitter Cards -->
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="/images/">
<meta name="twitter:title" content="Cross-validation">
<meta name="twitter:description" content="">
<meta name="twitter:creator" content="@soilmalone">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Cross-validation">
<meta property="og:description" content="">
<meta property="og:url" content="/DSM_book/pages/dsm_cont/cv/">
<meta property="og:site_name" content="Smart Digital Agriculture">

<meta name="google-site-verification" content="googledd99b1430269a639.html">



<link rel="canonical" href="/DSM_book/pages/dsm_cont/cv/">
<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Smart Digital Agriculture Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<!-- Bootstrap Core CSS -->
<link rel="stylesheet" href="/assets/css/bootstrap.min.css">
<!-- Clean Blog CSS -->
<link rel="stylesheet" href="/assets/css/clean-blog.css">
<!-- HPSTR main CSS -->
<link rel="stylesheet" href="/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Custom Fonts -->
<link href="//fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">
<link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
<link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Viga|Ubuntu:700' rel='stylesheet' type='text/css'>
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/images/apple-touch-icon-144x144-precomposed.png">



<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

</head>

<body id="page" >

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Smart Digital Agriculture</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                
                    
                    <li><a href="/" >Home</a></li>
                
                    
                    <li><a href="/publications/" >Publications</a></li>
                
                    
                    <li><a href="/software/" >Software</a></li>
                
                    
                    <li><a href="/blog/" >Journal Digests</a></li>
                
                    
                    <li><a href="/UseCases/" >Blog</a></li>
                
                    
                    <li><a href="/DSM_book/" >Using R for Digital Soil Mapping</a></li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

<!-- Page Header -->
<header class="intro-header" style="background-image: url('/images/pedometric2017.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="site-heading">
                    <h1>Cross-validation</h1>
                    
                        <hr class="small">
                        <span class="subheading"></span>
                    
                </div>
            </div>
        </div>
    </div>
</header>

<!--

-->

<div id="main" role="main">
  <article class="hentry">
    <!--
    <header class="header-title">
      <div class="header-title-wrap">
        <h1 class="entry-title">Cross-validation</h1>
        
        <p class="entry-reading-time">
          <i class="fa fa-clock-o"></i>
          
          Reading time ~18 minutes
        </p>
        
      </div>
    </header>
    -->
    <div class="entry-content">
      <h3 id="cross-validation">Cross-validation</h3>

<p>On the <a href="/DSM_book/pages/dsm_cont/goof/">goodness of fit</a> we
performed an assessment of the <code class="highlighter-rouge">mod.1</code> model which was a regression to
predict soil CEC from clay content.</p>

<p>Usually it is more appropriate however to validate a model using data
that was not included for model fitting. Model validation has a few
different forms and we will cover the main ones on this page.</p>

<ul>
  <li><a href="#s-1">Leave-one-out-cross-validation</a></li>
  <li><a href="#s-2">Random holdback</a></li>
  <li><a href="#s-3">k-fold cross-validation</a></li>
  <li><a href="#s-4">Bootstrapping</a></li>
</ul>

<h3 id="general-background-notes">General background notes</h3>

<p>For completely unbiased assessments of model quality, it is ideal to
have an additional data set that is completely independent of the model
data. When we are validating trained models with some sort of data
sub-setting mechanism, always keep in mind that the validation
statitsics will be biased. As Brus, Kempen, and Heuvelink (2011)
explains, the sampling from the target mapping area to be used for DSM
is more often than not from legacy soil survey, to which would not have
been based on a probability sampling design. Therefore, that sample will
be biased i.e not a true representation of the total population. Even
though we may randomly select observations from the legacy soil survey
sites, those vlidation points do not become a probaility sample of the
target area, and consequently will only provide biased estimates of
model quality. Thus an independent probaility sample is required.
Further ideas on the statisical valdation of models can be found in
Hastie, Tibshirani, and Friedman (2001). It is recommended that some
flavor of random sampling from the target area be conducted, to which
there are a few types such as simple random sampling and stratified
simple random sampling. Further information regarding sampling, sampling
desgings, their formulation and the relative advantages and constraints
of each are described in Gruijter et al. (2006).</p>

<p>Usually from an operational perspective it is difficult to arrange the
additional costs of organising and implementing some sort of probability
sampling for determining unbiased model quality assessment. The
alternative is to perform some sort of data sub-setting, such that with
a data set we split it into a set for model calibration and another set
for validation. This type of procedure can take different forms: the two
main ones being random-hold back and leave-one-out-cross-validation
(LOCV). Random-hold back (or sometimes k-fold validation) is where we
may sample a data set of some pre-determined proportion (say 70%) for
which is used for model calibration. We then validate the model using
the other 30% of the data. This is usually done using sampling with
replacement which is when a case has been selected, it is never offered
up for sampling again. The alternative is sampling with replacement
which is where a sample that has been selected is again put back into
the main set, making it possible for this same case be sampled again.
Sample with replacment does not change the underlying probabilities that
a case will be sampled. This is not the case for sampling without
replacment. Bootstrapping is the common term to describe the
cross-validation technique whereby the sample size s3% (unique cases) of
the data being selected for calibration (Efron and Tibshirani 1997).</p>

<p>For k-fold validation we divide the data set into equal sized partitions
or folds, with all but one of the folds being used for the model
calibration, the remaining fold is used for validation. We could repeat
this k-fold process a number of times, each time using a different
random sample from the data set for model calibration and validation.
This allows one to efficently derive distributions of the validation
statisics as a means of assessing the stability and sensitivity of the
models and parameters. A variant of the k-fold cross-validation is
spatial cross-validation (Lovelace, Nowosad, and Muenchow 2019) where
instead of random subsets of data to act as the different folds, the
data are clustered spatially into groups (which we can think of as folds
to keep with the general idea). Randomly splitting spatial data can lead
to training points that are neighbors in space with test points. Due to
spatial autocorrelation there is a chance the calibration and validation
datasets may not be independent, with the consequence that CV fails to
detect a possible overfitting. We will explore spatial cross-validation
once we start usng spatial data in further exercises.</p>

<p>For now lets just focus on conventional CV techniques to bed done some
fundmental concepts. You may note the some R packages concerned with
data modelling have some inbuilt techniques for cross-validation. The
<a href="https://topepo.github.io/caret/index.html">caret R package</a> is one of
these. Nonetheless it is always useful to know the mechanics of the
approaches.</p>

<p>Now lets get the data orgranised.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">ithir</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">MASS</span><span class="p">)</span><span class="w">
</span><span class="n">data</span><span class="p">(</span><span class="n">USYD_soil1</span><span class="p">)</span><span class="w">
</span><span class="n">soil.data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">USYD_soil1</span><span class="w">
</span><span class="n">mod.data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">na.omit</span><span class="p">(</span><span class="n">soil.data</span><span class="p">[,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"clay"</span><span class="p">,</span><span class="w"> </span><span class="s2">"CEC"</span><span class="p">)])</span><span class="w">
</span></code></pre></div></div>

<p><a href="#top">Back to top</a></p>

<h3 id="leave-one-out-cross-validation-">Leave-One-Out Cross Validation <a id="s-1"></a></h3>

<p>LOCV follows the logic that if we had <code class="highlighter-rouge">n</code> number of data, we would
subset <code class="highlighter-rouge">n-1</code> of these data, and fit a model with these data. Using this
model we would make a prediction for the single data that was left out
of the model (and save the residual). This is repeated for all <code class="highlighter-rouge">n</code>. LOCV
would be undertaken when there are very few data to work with. When we
can sacrifice a few data points, the random-hold back or k-fold
cross-validation or a bootstapping procedure would be acceptable.</p>

<p>At the most basic level, LOCV involves the use of a looping function or
<code class="highlighter-rouge">for</code> loop. Essentially they can be used to great effect when we want to
perform a particular analysis over-and-over which was done above for the
repeated random subsetting. For example with LOCV, for each iteration or
loop we take a subset of <code class="highlighter-rouge">n-1</code> rows and fit a model to them, then use
that model to predict for the point left out of the calibration.
Computationally it will look something like below.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">looPred</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">numeric</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">mod.data</span><span class="p">))</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">mod.data</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">looModel</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">CEC</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">clay</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.data</span><span class="p">[</span><span class="o">-</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
    </span><span class="n">looPred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">looModel</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="p">])</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>The <code class="highlighter-rouge">i</code> here is the counter, so for each loop it increases by 1 until we
get to the end of the data set. As you can see, we can index the
<code class="highlighter-rouge">mod.data</code> using the <code class="highlighter-rouge">i</code>, meaning that for each loop we will have
selected a different calibration set. On each loop, the prediction on
the point left out of the calibration is made onto the corresponding row
position of the <code class="highlighter-rouge">looPred</code> object. Again we can assess the performance of
the LOCV using the <code class="highlighter-rouge">goof</code> function.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">goof</span><span class="p">(</span><span class="n">predicted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">looPred</span><span class="p">,</span><span class="w"> </span><span class="n">observed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.data</span><span class="o">$</span><span class="n">CEC</span><span class="p">)</span><span class="w">

</span><span class="c1">##          R2 concordance      MSE     RMSE        bias</span><span class="w">
</span><span class="c1">## 1 0.4064735   0.5790589 14.47653 3.804804 0.005758669</span><span class="w">
</span></code></pre></div></div>

<p>LOCV will generally be less sensitive to outliers, so overall these
external validation results are not too different to those when we
performed the internal validation. Make a plot of the LOCV results to
visually compare against the internal validation.</p>

<p><a href="#top">Back to top</a></p>

<h3 id="random-holdback-subsetting-">Random holdback subsetting <a id="s-2"></a></h3>

<p>We will do the random-back validation using 70% of the data for
calibration. A random sample of the data will be performed using the
<code class="highlighter-rouge">sample</code> function.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span><span class="w">
</span><span class="n">training</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">mod.data</span><span class="p">),</span><span class="w"> </span><span class="m">0.7</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">nrow</span><span class="p">(</span><span class="n">mod.data</span><span class="p">),</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">training</span><span class="w">

</span><span class="c1">##   [1]  14  50 118  43 146 144  90  91 139  92  99  72  26   7  78  81 143 103</span><span class="w">
</span><span class="c1">##  [19] 117  76  15  32 106 109 133   9  41  74  23  27  60  53 122 115 128  96</span><span class="w">
</span><span class="c1">##  [37]  38  89  34  93  69 135 127  63  13  82  97 138  25 110  21  79 120  47</span><span class="w">
</span><span class="c1">##  [55] 140 116  16   6 105  86  87  39  31 131 145 108   4 102 124  98  52  22</span><span class="w">
</span><span class="c1">##  [73] 125  77  35  40  30  12  84  70  64 142  29 119 114   3 141  54  58 126</span><span class="w">
</span><span class="c1">##  [91] 111  37   8  51  10 101  42  44  83 104  75 132</span><span class="w">
</span></code></pre></div></div>

<p>These values correspond to row numbers which will correspond to the row
which we will use for the calibration data. We subset these rows out of
<code class="highlighter-rouge">mod.data</code> and fit a new linear model.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mod.rh</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">CEC</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">clay</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.data</span><span class="p">[</span><span class="n">training</span><span class="p">,</span><span class="w"> </span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div>

<p>So lets evaluate the calibration model with <code class="highlighter-rouge">goof</code>:</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">goof</span><span class="p">(</span><span class="n">predicted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.rh</span><span class="o">$</span><span class="n">fitted.values</span><span class="p">,</span><span class="w"> </span><span class="n">observed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.data</span><span class="o">$</span><span class="n">CEC</span><span class="p">[</span><span class="n">training</span><span class="p">])</span><span class="w">

</span><span class="c1">##          R2 concordance      MSE    RMSE bias</span><span class="w">
</span><span class="c1">## 1 0.3658025   0.5304079 15.55893 3.94448    0</span><span class="w">
</span></code></pre></div></div>

<p>But we are more interested in how this model performs when we use the
validation data. Here we use the <code class="highlighter-rouge">predict</code> function to predict upon this
data.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mod.rh.V</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">mod.rh</span><span class="p">,</span><span class="w"> </span><span class="n">mod.data</span><span class="p">[</span><span class="o">-</span><span class="n">training</span><span class="p">,</span><span class="w"> </span><span class="p">])</span><span class="w">
</span><span class="n">goof</span><span class="p">(</span><span class="n">predicted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.rh.V</span><span class="p">,</span><span class="w"> </span><span class="n">observed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.data</span><span class="o">$</span><span class="n">CEC</span><span class="p">[</span><span class="o">-</span><span class="n">training</span><span class="p">])</span><span class="w">

</span><span class="c1">##          R2 concordance      MSE     RMSE       bias</span><span class="w">
</span><span class="c1">## 1 0.5395843   0.6613833 10.83252 3.291279 -0.1277488</span><span class="w">
</span></code></pre></div></div>

<p>A good indicator of model generalisation is that the validation
statisitcs are near or better than that found for model calibration.
Model overfitting is evident when there is a large discrepancy. Set the
<code class="highlighter-rouge">plot.it</code> parameter to <code class="highlighter-rouge">TRUE</code> and re-run the script above and you will
see a plot like the figure below.</p>

<figure>
    <img src="/images/dsm_book/extVal.png" alt="rconsole" />
    <figcaption> Observed vs. predicted plot of CEC model (validation data set) with line of concordance (red line).</figcaption>
</figure>

<p>The <code class="highlighter-rouge">mod.rh</code> model does not appear to perform too bad after all. A few
of the high observed values contribute greatly to the validation
diagnostics. A couple of methods are available to assess the sensitivity
of these results. The first is to remove what could potentially be
outliers from the data. The second is to perform a sensitivity analysis
which would include interating the data sub-setting procedure and
evaluate the validation statistics each time to get a sense how much
they vary.</p>

<p>In the example below this is demstrated by repeating the random
subsetting 5 times. Note that you could do this many more times over.
Notes also the removal of the <code class="highlighter-rouge">set.seed</code> function as we need to take a
new subset for each iteration. This will also mean that the final
results shown below and what you generate will be slightly different.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># repeated random subsetting place to store results</span><span class="w">
</span><span class="n">validation.outs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">6</span><span class="p">)</span><span class="w">

</span><span class="c1"># repeat subsetting and model fitting</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">training</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">mod.data</span><span class="p">),</span><span class="w"> </span><span class="m">0.7</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">nrow</span><span class="p">(</span><span class="n">mod.data</span><span class="p">),</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
    </span><span class="n">mod.rh</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">CEC</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">clay</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.data</span><span class="p">[</span><span class="n">training</span><span class="p">,</span><span class="w"> </span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
    </span><span class="n">mod.rh.V</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">mod.rh</span><span class="p">,</span><span class="w"> </span><span class="n">mod.data</span><span class="p">[</span><span class="o">-</span><span class="n">training</span><span class="p">,</span><span class="w"> </span><span class="p">])</span><span class="w">
    </span><span class="n">validation.outs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">i</span><span class="w">
    </span><span class="n">validation.outs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="o">:</span><span class="m">6</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.matrix</span><span class="p">(</span><span class="n">goof</span><span class="p">(</span><span class="n">predicted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.rh.V</span><span class="p">,</span><span class="w"> </span><span class="n">observed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.data</span><span class="o">$</span><span class="n">CEC</span><span class="p">[</span><span class="o">-</span><span class="n">training</span><span class="p">]))</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="n">validation.outs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">validation.outs</span><span class="p">)</span><span class="w">
</span><span class="nf">names</span><span class="p">(</span><span class="n">validation.outs</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"iteration"</span><span class="p">,</span><span class="w"> </span><span class="s2">"R2"</span><span class="p">,</span><span class="w"> </span><span class="s2">"concordance"</span><span class="p">,</span><span class="w"> </span><span class="s2">"MSE"</span><span class="p">,</span><span class="w"> </span><span class="s2">"RMSE"</span><span class="p">,</span><span class="w"> </span><span class="s2">"bias"</span><span class="p">)</span><span class="w">

</span><span class="c1"># print outputs</span><span class="w">
</span><span class="n">validation.outs</span><span class="w">

</span><span class="c1">##   iteration        R2 concordance       MSE     RMSE       bias</span><span class="w">
</span><span class="c1">## 1         1 0.5403760   0.6735857 13.467984 3.669875  0.6320056</span><span class="w">
</span><span class="c1">## 2         2 0.3707397   0.5200623 17.925045 4.233798 -1.1412116</span><span class="w">
</span><span class="c1">## 3         3 0.6174596   0.7442635  5.734524 2.394687  0.2961916</span><span class="w">
</span><span class="c1">## 4         4 0.4390767   0.5909275  9.697983 3.114159  0.2976717</span><span class="w">
</span><span class="c1">## 5         5 0.2138451   0.4567065 21.587716 4.646258 -1.8841137</span><span class="w">
</span></code></pre></div></div>

<p><a href="#top">Back to top</a></p>

<h4 id="k-fold-cross-validation-">K-fold cross-validation <a id="s-3"></a></h4>

<p>As the name suggests, k-fold cross-validation is about creating a
defined number of folds or subsets in the whole data, fitting the model
with a given number of folds and then vlidating the model with the other
remaining folds. For example if we impose four folds in the available
data, we could fit the model with three of the folds and validate on the
fourth one. In the example below the folds are randomly assigned to each
case, but could be imposed differently for example with a sptatial
clustering in order to implement a spatial cross-validation procedure.
In the example below we repeat the four fold cross-validation 1000
times, in which case we would call the a repeated four fold
cross-validation.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Set up matrix to store goodness of fit statistics for each model 4 fold</span><span class="w">
</span><span class="c1"># repeated 1000 times = 4000 models</span><span class="w">
</span><span class="n">validation.outs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4000</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">6</span><span class="p">)</span><span class="w">

</span><span class="c1"># repeat subsetting and model fitting</span><span class="w">
</span><span class="n">cnt</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">j</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">1000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1"># set up folds</span><span class="w">
    </span><span class="n">folds</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nrow</span><span class="p">(</span><span class="n">mod.data</span><span class="p">))</span><span class="w">
    </span><span class="c1"># random permutation</span><span class="w">
    </span><span class="n">rs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">mod.data</span><span class="p">),</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">
    </span><span class="n">rs.folds</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">folds</span><span class="p">[</span><span class="n">order</span><span class="p">(</span><span class="n">rs</span><span class="p">)]</span><span class="w">
    
    </span><span class="c1"># model fitting for each combination of folds</span><span class="w">
    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">4</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="n">training</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">which</span><span class="p">(</span><span class="n">rs.folds</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w">
        </span><span class="n">mod.rh</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">CEC</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">clay</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.data</span><span class="p">[</span><span class="n">training</span><span class="p">,</span><span class="w"> </span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
        </span><span class="n">mod.rh.V</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">mod.rh</span><span class="p">,</span><span class="w"> </span><span class="n">mod.data</span><span class="p">[</span><span class="o">-</span><span class="n">training</span><span class="p">,</span><span class="w"> </span><span class="p">])</span><span class="w">
        </span><span class="n">validation.outs</span><span class="p">[</span><span class="n">cnt</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cnt</span><span class="w">
        </span><span class="n">validation.outs</span><span class="p">[</span><span class="n">cnt</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="o">:</span><span class="m">6</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.matrix</span><span class="p">(</span><span class="n">goof</span><span class="p">(</span><span class="n">predicted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.rh.V</span><span class="p">,</span><span class="w"> </span><span class="n">observed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.data</span><span class="o">$</span><span class="n">CEC</span><span class="p">[</span><span class="o">-</span><span class="n">training</span><span class="p">]))</span><span class="w">
        </span><span class="n">cnt</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cnt</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="n">validation.outs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">validation.outs</span><span class="p">)</span><span class="w">
</span><span class="nf">names</span><span class="p">(</span><span class="n">validation.outs</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"iteration"</span><span class="p">,</span><span class="w"> </span><span class="s2">"R2"</span><span class="p">,</span><span class="w"> </span><span class="s2">"concordance"</span><span class="p">,</span><span class="w"> </span><span class="s2">"MSE"</span><span class="p">,</span><span class="w"> </span><span class="s2">"RMSE"</span><span class="p">,</span><span class="w"> </span><span class="s2">"bias"</span><span class="p">)</span><span class="w">

</span><span class="c1"># averaged goodness of fit meansures</span><span class="w">
</span><span class="n">apply</span><span class="p">(</span><span class="n">validation.outs</span><span class="p">[,</span><span class="w"> </span><span class="m">2</span><span class="o">:</span><span class="m">6</span><span class="p">],</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">)</span><span class="w">

</span><span class="c1">##           R2  concordance          MSE         RMSE         bias </span><span class="w">
</span><span class="c1">##  0.398731466  0.572562985 14.530480367  3.744664092  0.006906522</span><span class="w">

</span><span class="c1"># standard deviation of goodness of fit meansures</span><span class="w">
</span><span class="n">apply</span><span class="p">(</span><span class="n">validation.outs</span><span class="p">[,</span><span class="w"> </span><span class="m">2</span><span class="o">:</span><span class="m">6</span><span class="p">],</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="p">)</span><span class="w">

</span><span class="c1">##          R2 concordance         MSE        RMSE        bias </span><span class="w">
</span><span class="c1">##  0.12564317  0.09799382  5.54250995  0.71281009  0.72051238</span><span class="w">
</span></code></pre></div></div>

<p><a href="#top">Back to top</a></p>

<h3 id="bootstrapping-">Bootstrapping <a id="s-4"></a></h3>

<p>If the size of a data set has <em>n</em> number of cases, as described earlier,
the bootstrap cross validation involves selecting <em>n</em> number of cases
with replacement. However because sampling s done with replacment only
about 63% of cases are selected. The other 37% can therefore be used as
a validation dataset (Efron and Tibshirani 1997). Below we repeat the
bootstrapping 4000 times and then estimate the avraged goodness of fit
measures and the standard deviation of those too.</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Set up matrix to store goodness of fit statistics for each model of the 4000</span><span class="w">
</span><span class="c1"># models</span><span class="w">
</span><span class="n">validation.outs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4000</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">6</span><span class="p">)</span><span class="w">

</span><span class="c1"># repeat subsetting and model fitting repeat subsetting and model fitting</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">j</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">4000</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="c1"># sample with replacement</span><span class="w">
    </span><span class="n">rs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">mod.data</span><span class="p">),</span><span class="w"> </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">)</span><span class="w">
    </span><span class="c1"># get the unique cases</span><span class="w">
    </span><span class="n">urs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">unique</span><span class="p">(</span><span class="n">rs</span><span class="p">)</span><span class="w">
    </span><span class="c1"># calibration data</span><span class="w">
    </span><span class="n">cal.dat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mod.data</span><span class="p">[</span><span class="n">urs</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w">
    </span><span class="c1"># validation data</span><span class="w">
    </span><span class="n">val.dat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mod.data</span><span class="p">[</span><span class="o">-</span><span class="n">urs</span><span class="p">,</span><span class="w"> </span><span class="p">]</span><span class="w">
    
    </span><span class="c1"># model fitting</span><span class="w">
    </span><span class="n">mod.rh</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="n">CEC</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">clay</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cal.dat</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
    </span><span class="n">mod.rh.V</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">mod.rh</span><span class="p">,</span><span class="w"> </span><span class="n">val.dat</span><span class="p">)</span><span class="w">
    </span><span class="n">validation.outs</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cnt</span><span class="w">
    </span><span class="n">validation.outs</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="o">:</span><span class="m">6</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.matrix</span><span class="p">(</span><span class="n">goof</span><span class="p">(</span><span class="n">predicted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mod.rh.V</span><span class="p">,</span><span class="w"> </span><span class="n">observed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">val.dat</span><span class="o">$</span><span class="n">CEC</span><span class="p">))</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="n">validation.outs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">validation.outs</span><span class="p">)</span><span class="w">
</span><span class="nf">names</span><span class="p">(</span><span class="n">validation.outs</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"iteration"</span><span class="p">,</span><span class="w"> </span><span class="s2">"R2"</span><span class="p">,</span><span class="w"> </span><span class="s2">"concordance"</span><span class="p">,</span><span class="w"> </span><span class="s2">"MSE"</span><span class="p">,</span><span class="w"> </span><span class="s2">"RMSE"</span><span class="p">,</span><span class="w"> </span><span class="s2">"bias"</span><span class="p">)</span><span class="w">

</span><span class="c1"># averaged goodness of fit meansures</span><span class="w">
</span><span class="n">apply</span><span class="p">(</span><span class="n">validation.outs</span><span class="p">[,</span><span class="w"> </span><span class="m">2</span><span class="o">:</span><span class="m">6</span><span class="p">],</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">)</span><span class="w">

</span><span class="c1">##           R2  concordance          MSE         RMSE         bias </span><span class="w">
</span><span class="c1">##  0.398374260  0.574861262 14.587025983  3.779626669  0.006002626</span><span class="w">

</span><span class="c1"># standard deviation of goodness of fit meansures</span><span class="w">
</span><span class="n">apply</span><span class="p">(</span><span class="n">validation.outs</span><span class="p">[,</span><span class="w"> </span><span class="m">2</span><span class="o">:</span><span class="m">6</span><span class="p">],</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="p">)</span><span class="w">

</span><span class="c1">##          R2 concordance         MSE        RMSE        bias </span><span class="w">
</span><span class="c1">##  0.09757849  0.07662582  4.19643649  0.54911165  0.64825113</span><span class="w">
</span></code></pre></div></div>

<p><a href="#top">Back to top</a></p>

<h3 id="references">References</h3>

<p>Brus, D., B. Kempen, and G.B.M. Heuvelink. 2011. Sampling for
Validation of Digital Soil Maps. <em>European Journal of Soil Science</em> 62
(3): 394407.</p>

<p>Efron, Bradley, and Robert Tibshirani. 1997. Improvements on
Cross-Validation: The .632+ Bootstrap Method. <em>Journal of the American
Statistical Association</em> 92 (438). [American Statistical Association,
Taylor &amp; Francis, Ltd.]: 54860. <a href="http://www.jstor.org/stable/2965703">http://www.jstor.org/stable/2965703</a>.</p>

<p>Gruijter, J. de, D.J. Brus, M.F.P. Bierkens, and M. Knotters. 2006.
<em>Sampling for Natural Resource Monitoring</em>. Berlin Heidelberg:
Springer-Verlag.</p>

<p>Hastie, T., R. Tibshirani, and J Friedman. 2001. <em>The Elements of
Statistical Learning</em>. New York, NY: Springer.</p>

<p>Lovelace, R., J Nowosad, and J Muenchow. 2019. <em>Geocomputation with R</em>.
Chapman; Hall/CRC.</p>

      <footer class="entry-meta">
        <span>Updated on <span class="entry-date date published updated"><time datetime="2020-07-26">July 26, 2020</time></span></span>
        <span class="author vcard"><span class="fn">Smart Digital Agriculture</span></span>
        <div class="social-share">
  <ul class="socialcount socialcount-small inline-list">
    <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=/DSM_book/pages/dsm_cont/cv/" title="Share on Facebook"><span class="count"><i class="fa fa-facebook-square"></i> Like</span></a></li>
    <li class="twitter"><a href="https://twitter.com/intent/tweet?text=/DSM_book/pages/dsm_cont/cv/" title="Share on Twitter"><span class="count"><i class="fa fa-twitter-square"></i> Tweet</span></a></li>
    <li class="googleplus"><a href="https://plus.google.com/share?url=/DSM_book/pages/dsm_cont/cv/" title="Share on Google Plus"><span class="count"><i class="fa fa-google-plus-square"></i> +1</span></a></li>
  </ul>
</div><!-- /.social-share -->
      </footer>
    </div><!-- /.entry-content -->
    
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
    <!--<span>&copy; 2021 Smart Digital Agriculture. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/hpstr/" rel="notfollow">HPSTR Theme</a>.</span>-->

<footer role="contentinfo">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    <li>
                        <a href="/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="mailto:malone.brendan1001@gmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://github.com/brendo1001">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://twitter.com/soilmalone">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                </ul>
                <p class="copyright text-muted">Copyright &copy; Smart Digital Agriculture 2021, All Rights Reserved.</p>
            </div>
        </div>
    </div>
</footer>

</div><!-- /.footer-wrapper -->

<!-- JQuery JavaScript -->
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>

<!-- Bootstrap Core JavaScript -->
<script src="/assets/js/vendor/bootstrap.min.js"></script>

<!-- Clean Blog JavaScript -->
<script src="/assets/js/clean-blog.min.js"></script>

<script src="/assets/js/scripts.min.js"></script>


<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87285093-1', 'auto');
  ga('require', 'linkid', 'linkid.js');
  ga('send', 'pageview');
</script>


<!-- Math equation support by MathJax -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
            equationNumbers: { autoNumber: "all" },
            inlineMath: [['$','$'],['\\(','\\)']],
        },
        "HTML-CSS": {
            availableFonts: ["TeX"],
            preferredFont: "TeX",
        },
    });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>




</body>
</html>
